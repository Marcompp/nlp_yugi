{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c971386c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c971386c",
    "outputId": "c32938f7-6ce5-4b57-843a-9ceaff00f6d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6121fa51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "6121fa51",
    "outputId": "a7bd778f-242c-472c-aa8d-c551f2da6b33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_5728\\1007175427.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_yugi = pd.read_csv('dbs/yugi_comp.csv',engine=\"python\",error_bad_lines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Price</th>\n",
       "      <th>isGood</th>\n",
       "      <th>text</th>\n",
       "      <th>card_type</th>\n",
       "      <th>type</th>\n",
       "      <th>family</th>\n",
       "      <th>atk</th>\n",
       "      <th>def</th>\n",
       "      <th>level</th>\n",
       "      <th>property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>XX-Saber Boggart Knight</td>\n",
       "      <td>Shatterfoil Rare</td>\n",
       "      <td>2.73</td>\n",
       "      <td>True</td>\n",
       "      <td>When this card is Normal Summoned: You can Spe...</td>\n",
       "      <td>monster</td>\n",
       "      <td>Beast-Warrior / Effect</td>\n",
       "      <td>earth</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gagaga Cowboy</td>\n",
       "      <td>Shatterfoil Rare</td>\n",
       "      <td>4.68</td>\n",
       "      <td>True</td>\n",
       "      <td>2 Level 4 monsters\\n\\nOnce per turn: You can d...</td>\n",
       "      <td>monster</td>\n",
       "      <td>Warrior / Xyz / Effect</td>\n",
       "      <td>earth</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Forbidden Chalice</td>\n",
       "      <td>Shatterfoil Rare</td>\n",
       "      <td>2.09</td>\n",
       "      <td>True</td>\n",
       "      <td>Target 1 face-up monster on the field; until t...</td>\n",
       "      <td>spell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quick-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fairy Cheer Girl</td>\n",
       "      <td>Shatterfoil Rare</td>\n",
       "      <td>2.06</td>\n",
       "      <td>True</td>\n",
       "      <td>2 Level 4 Fairy-Type monsters\\n\\nYou can detac...</td>\n",
       "      <td>monster</td>\n",
       "      <td>Fairy / Xyz / Effect</td>\n",
       "      <td>light</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Exploder Dragon</td>\n",
       "      <td>Shatterfoil Rare</td>\n",
       "      <td>2.08</td>\n",
       "      <td>True</td>\n",
       "      <td>If this card is destroyed by battle and sent t...</td>\n",
       "      <td>monster</td>\n",
       "      <td>Dragon / Effect</td>\n",
       "      <td>earth</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     Name            Rarity  Price  isGood  \\\n",
       "0           0  XX-Saber Boggart Knight  Shatterfoil Rare   2.73    True   \n",
       "1           1            Gagaga Cowboy  Shatterfoil Rare   4.68    True   \n",
       "2           2        Forbidden Chalice  Shatterfoil Rare   2.09    True   \n",
       "3           3         Fairy Cheer Girl  Shatterfoil Rare   2.06    True   \n",
       "4           4          Exploder Dragon  Shatterfoil Rare   2.08    True   \n",
       "\n",
       "                                                text card_type  \\\n",
       "0  When this card is Normal Summoned: You can Spe...   monster   \n",
       "1  2 Level 4 monsters\\n\\nOnce per turn: You can d...   monster   \n",
       "2  Target 1 face-up monster on the field; until t...     spell   \n",
       "3  2 Level 4 Fairy-Type monsters\\n\\nYou can detac...   monster   \n",
       "4  If this card is destroyed by battle and sent t...   monster   \n",
       "\n",
       "                     type family     atk     def  level    property  \n",
       "0  Beast-Warrior / Effect  earth  1900.0  1000.0    4.0         NaN  \n",
       "1  Warrior / Xyz / Effect  earth  1500.0  2400.0    4.0         NaN  \n",
       "2                     NaN    NaN     NaN     NaN    NaN  Quick-Play  \n",
       "3    Fairy / Xyz / Effect  light  1900.0  1500.0    4.0         NaN  \n",
       "4         Dragon / Effect  earth  1000.0     0.0    3.0         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yugi = pd.read_csv('dbs/yugi_comp.csv',engine=\"python\",error_bad_lines=False)\n",
    "df_yugi = df_yugi.drop(['name'], axis=1)\n",
    "df_yugi = df_yugi[df_yugi['text'].notna()]\n",
    "df_yugi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0237e7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "c0237e7d",
    "outputId": "47dd01ed-cb03-4fa9-a4f1-61b350769bca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Price</th>\n",
       "      <th>isGood</th>\n",
       "      <th>text</th>\n",
       "      <th>card_type</th>\n",
       "      <th>type</th>\n",
       "      <th>family</th>\n",
       "      <th>atk</th>\n",
       "      <th>def</th>\n",
       "      <th>level</th>\n",
       "      <th>property</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>3267</td>\n",
       "      <td>Baby Dragon</td>\n",
       "      <td>Common</td>\n",
       "      <td>1.79</td>\n",
       "      <td>False</td>\n",
       "      <td>Much more than just a child, this dragon is gi...</td>\n",
       "      <td>monster</td>\n",
       "      <td>Dragon / Normal</td>\n",
       "      <td>wind</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         Name  Rarity  Price  isGood  \\\n",
       "3267        3267  Baby Dragon  Common   1.79   False   \n",
       "\n",
       "                                                   text card_type  \\\n",
       "3267  Much more than just a child, this dragon is gi...   monster   \n",
       "\n",
       "                 type family     atk    def  level property  \n",
       "3267  Dragon / Normal   wind  1200.0  700.0    3.0      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yugi.loc[(df_yugi['Name'] == \"Baby Dragon\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa04b37",
   "metadata": {
    "id": "3fa04b37"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def getMonsterType(row):\n",
    "    if row['card_type'] == 'monster':\n",
    "        monstype = row['type'].split(\"/\")\n",
    "        return monstype[-1].replace(\" \",\"\")\n",
    "    else:\n",
    "        return math.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb869144",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "bb869144",
    "outputId": "450dc283-1051-4dfa-e84f-9bc7c360ef1c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Price</th>\n",
       "      <th>isGood</th>\n",
       "      <th>text</th>\n",
       "      <th>card_type</th>\n",
       "      <th>type</th>\n",
       "      <th>family</th>\n",
       "      <th>atk</th>\n",
       "      <th>def</th>\n",
       "      <th>level</th>\n",
       "      <th>property</th>\n",
       "      <th>monster_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>XX-Saber Boggart Knight</td>\n",
       "      <td>Shatterfoil Rare</td>\n",
       "      <td>2.73</td>\n",
       "      <td>True</td>\n",
       "      <td>When this card is Normal Summoned: You can Spe...</td>\n",
       "      <td>monster</td>\n",
       "      <td>Beast-Warrior / Effect</td>\n",
       "      <td>earth</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gagaga Cowboy</td>\n",
       "      <td>Shatterfoil Rare</td>\n",
       "      <td>4.68</td>\n",
       "      <td>True</td>\n",
       "      <td>2 Level 4 monsters\\n\\nOnce per turn: You can d...</td>\n",
       "      <td>monster</td>\n",
       "      <td>Warrior / Xyz / Effect</td>\n",
       "      <td>earth</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Forbidden Chalice</td>\n",
       "      <td>Shatterfoil Rare</td>\n",
       "      <td>2.09</td>\n",
       "      <td>True</td>\n",
       "      <td>Target 1 face-up monster on the field; until t...</td>\n",
       "      <td>spell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quick-Play</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fairy Cheer Girl</td>\n",
       "      <td>Shatterfoil Rare</td>\n",
       "      <td>2.06</td>\n",
       "      <td>True</td>\n",
       "      <td>2 Level 4 Fairy-Type monsters\\n\\nYou can detac...</td>\n",
       "      <td>monster</td>\n",
       "      <td>Fairy / Xyz / Effect</td>\n",
       "      <td>light</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Exploder Dragon</td>\n",
       "      <td>Shatterfoil Rare</td>\n",
       "      <td>2.08</td>\n",
       "      <td>True</td>\n",
       "      <td>If this card is destroyed by battle and sent t...</td>\n",
       "      <td>monster</td>\n",
       "      <td>Dragon / Effect</td>\n",
       "      <td>earth</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Effect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     Name            Rarity  Price  isGood  \\\n",
       "0           0  XX-Saber Boggart Knight  Shatterfoil Rare   2.73    True   \n",
       "1           1            Gagaga Cowboy  Shatterfoil Rare   4.68    True   \n",
       "2           2        Forbidden Chalice  Shatterfoil Rare   2.09    True   \n",
       "3           3         Fairy Cheer Girl  Shatterfoil Rare   2.06    True   \n",
       "4           4          Exploder Dragon  Shatterfoil Rare   2.08    True   \n",
       "\n",
       "                                                text card_type  \\\n",
       "0  When this card is Normal Summoned: You can Spe...   monster   \n",
       "1  2 Level 4 monsters\\n\\nOnce per turn: You can d...   monster   \n",
       "2  Target 1 face-up monster on the field; until t...     spell   \n",
       "3  2 Level 4 Fairy-Type monsters\\n\\nYou can detac...   monster   \n",
       "4  If this card is destroyed by battle and sent t...   monster   \n",
       "\n",
       "                     type family     atk     def  level    property  \\\n",
       "0  Beast-Warrior / Effect  earth  1900.0  1000.0    4.0         NaN   \n",
       "1  Warrior / Xyz / Effect  earth  1500.0  2400.0    4.0         NaN   \n",
       "2                     NaN    NaN     NaN     NaN    NaN  Quick-Play   \n",
       "3    Fairy / Xyz / Effect  light  1900.0  1500.0    4.0         NaN   \n",
       "4         Dragon / Effect  earth  1000.0     0.0    3.0         NaN   \n",
       "\n",
       "  monster_type  \n",
       "0       Effect  \n",
       "1       Effect  \n",
       "2          NaN  \n",
       "3       Effect  \n",
       "4       Effect  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yugi['monster_type'] = df_yugi.apply(lambda row: getMonsterType(row), axis=1)\n",
    "df_yugi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe3c3f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fe3c3f8",
    "outputId": "eeb959b0-d8c5-49cc-952e-dd21466298d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Unnamed: 0                           Name            Rarity  Price  \\\n",
       "0               0        XX-Saber Boggart Knight  Shatterfoil Rare   2.73   \n",
       "1               1                  Gagaga Cowboy  Shatterfoil Rare   4.68   \n",
       "2               2              Forbidden Chalice  Shatterfoil Rare   2.09   \n",
       "3               3               Fairy Cheer Girl  Shatterfoil Rare   2.06   \n",
       "4               4                Exploder Dragon  Shatterfoil Rare   2.08   \n",
       "...           ...                            ...               ...    ...   \n",
       "11642       11642        Herald of Mirage Lights        Ultra Rare   1.55   \n",
       "11643       11643   Graveyard of Wandering Souls        Ultra Rare   1.39   \n",
       "11644       11644  Lib the World Key Blademaster        Ultra Rare   3.47   \n",
       "11645       11645                   Kingyo Sukui        Ultra Rare   1.22   \n",
       "11646       11646               Skydive Scorcher        Ultra Rare   1.58   \n",
       "\n",
       "       isGood                                               text card_type  \\\n",
       "0        True  When this card is Normal Summoned: You can Spe...   monster   \n",
       "1        True  2 Level 4 monsters\\n\\nOnce per turn: You can d...   monster   \n",
       "2        True  Target 1 face-up monster on the field; until t...     spell   \n",
       "3        True  2 Level 4 Fairy-Type monsters\\n\\nYou can detac...   monster   \n",
       "4        True  If this card is destroyed by battle and sent t...   monster   \n",
       "...       ...                                                ...       ...   \n",
       "11642   False  2 monsters with the same Type and Attribute, e...   monster   \n",
       "11643   False  If this card is already face-up on the field:\\...      trap   \n",
       "11644   False  2 monsters\\n\\nCan only be Link Summoned while ...   monster   \n",
       "11645   False  You can target 1 monster in your opponent's GY...      trap   \n",
       "11646   False  Target 1 \"Elemental HERO\" Fusion Monster you c...     spell   \n",
       "\n",
       "                          type family     atk     def  level    property  \\\n",
       "0       Beast-Warrior / Effect  earth  1900.0  1000.0    4.0         NaN   \n",
       "1       Warrior / Xyz / Effect  earth  1500.0  2400.0    4.0         NaN   \n",
       "2                          NaN    NaN     NaN     NaN    NaN  Quick-Play   \n",
       "3         Fairy / Xyz / Effect  light  1900.0  1500.0    4.0         NaN   \n",
       "4              Dragon / Effect  earth  1000.0     0.0    3.0         NaN   \n",
       "...                        ...    ...     ...     ...    ...         ...   \n",
       "11642    Fairy / Link / Effect  light   600.0     0.0    0.0         NaN   \n",
       "11643                      NaN    NaN     NaN     NaN    NaN  Continuous   \n",
       "11644  Cyberse / Link / Effect  light  2000.0     0.0    0.0         NaN   \n",
       "11645                      NaN    NaN     NaN     NaN    NaN  Continuous   \n",
       "11646                      NaN    NaN     NaN     NaN    NaN      Normal   \n",
       "\n",
       "      monster_type  \n",
       "0           Effect  \n",
       "1           Effect  \n",
       "2              NaN  \n",
       "3           Effect  \n",
       "4           Effect  \n",
       "...            ...  \n",
       "11642       Effect  \n",
       "11643          NaN  \n",
       "11644       Effect  \n",
       "11645          NaN  \n",
       "11646          NaN  \n",
       "\n",
       "[11368 rows x 14 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yu = df_yugi.loc[(df_yugi['monster_type'] != 'Normal')]\n",
    "df_yu.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cfdd5e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "3cfdd5e7",
    "outputId": "2ad39021-3dad-41dc-ff45-80f5abd6a77f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Price</th>\n",
       "      <th>isGood</th>\n",
       "      <th>text</th>\n",
       "      <th>card_type</th>\n",
       "      <th>type</th>\n",
       "      <th>family</th>\n",
       "      <th>atk</th>\n",
       "      <th>def</th>\n",
       "      <th>level</th>\n",
       "      <th>property</th>\n",
       "      <th>monster_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Name, Rarity, Price, isGood, text, card_type, type, family, atk, def, level, property, monster_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yu.loc[(df_yu['Name'] == \"Baby Dragon\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd2b9bb",
   "metadata": {
    "id": "4cd2b9bb"
   },
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0c794",
   "metadata": {
    "id": "b9c0c794",
    "outputId": "99598c00-62a4-4c9f-e898-074a3870f6bd"
   },
   "outputs": [],
   "source": [
    "dfg = df_yugi.query(\"isGood\")\n",
    "dfb = df_yugi.query(\"not isGood\")\n",
    "dfg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854bc48",
   "metadata": {
    "id": "3854bc48"
   },
   "outputs": [],
   "source": [
    "def get_term(dict, search_index):\n",
    "    return list(dict.keys())[list(dict.values()).index(search_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d428fd9",
   "metadata": {
    "id": "3d428fd9"
   },
   "outputs": [],
   "source": [
    "def word_frequencies(tfidf):\n",
    "    tfidfadd = []\n",
    "    words = []\n",
    "    for j in range(tfidf.shape[1]):\n",
    "        words.append(get_term(vectorizer.vocabulary_,j))\n",
    "        tfidfadd.append(0)\n",
    "        for i in range(tfidf.shape[0]):            \n",
    "            tfidfadd[j] += tfidf[i, j]\n",
    "    return tfidfadd, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf9a1d6",
   "metadata": {
    "id": "fdf9a1d6"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import heapq\n",
    "\n",
    "\n",
    "def get_top_words(n,tfidf):\n",
    "    tfdfadd, words = word_frequencies(tfidf)\n",
    "    return get_top(n,tfdfadd,words)\n",
    "\n",
    "def get_top(n,tfidfadd,words):\n",
    "    stopwords = [\"2000\",\"1000\",\"100\"]\n",
    "    sw = []\n",
    "    for stopword in stopwords:\n",
    "        sw.append(words.index(stopword))\n",
    "    \n",
    "\n",
    "    tops = list(list(zip(*heapq.nlargest(n, enumerate(tfidfadd), key=operator.itemgetter(1))))[0])\n",
    "    print(tops)\n",
    "    \n",
    "    for word in list(tops):  # iterating on a copy since removing will mess things up\n",
    "        if word in sw:\n",
    "            tops.remove(word)\n",
    "            print(tops)\n",
    "    res = 0\n",
    "    while (len(tops) < n):\n",
    "        print(len(tops))\n",
    "        res += n - len(tops)\n",
    "        tops = list(list(zip(*heapq.nlargest(n+res, enumerate(tfidfadd), key=operator.itemgetter(1))))[0])\n",
    "        print(f\"res{res}\")\n",
    "        for word in list(tops):\n",
    "            if word in sw:\n",
    "                tops.remove(word)\n",
    "        \n",
    "    \n",
    "    values = []\n",
    "    labels = []\n",
    "    tot = 0\n",
    "    \n",
    "    for j in tops:\n",
    "        values.append(tfidfadd[j]/len(tfidfadd))\n",
    "        labels.append(words[j])\n",
    "\n",
    "    #for j in range(len(tfidfadd)):\n",
    "    #    if j in tops:\n",
    "    #        values.append(tfidfadd[j]/len(tfidfadd))\n",
    "    #        labels.append(words[j])\n",
    "    #    else:\n",
    "    #        tot += tfidfadd[j]/len(tfidfadd)\n",
    "    #values.append(tot)\n",
    "    #labels.append(\"Other\")\n",
    "    return values, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4422c0a",
   "metadata": {
    "id": "b4422c0a"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Compute the TF-IDF matrix\n",
    "tfidf_g = vectorizer.fit_transform(dfg[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f29af3",
   "metadata": {
    "id": "15f29af3"
   },
   "outputs": [],
   "source": [
    "tfidf_b = vectorizer.fit_transform(dfb[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d737bb5",
   "metadata": {
    "id": "0d737bb5",
    "outputId": "a97a1104-7769-4524-eb72-0d379664177e"
   },
   "outputs": [],
   "source": [
    "tfdfadd_g, words_g = word_frequencies(tfidf_g)\n",
    "print(\"foi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80195d0",
   "metadata": {
    "id": "d80195d0",
    "outputId": "44b3b842-9f5e-4af2-909b-c2f4cf371c47"
   },
   "outputs": [],
   "source": [
    "values, labels = get_top(30,tfdfadd_g,words_g)\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "plt.title(\"Most frequent words / Good\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar(labels,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b23efe",
   "metadata": {
    "id": "e5b23efe",
    "outputId": "c60c9907-ce3a-494f-adfb-f555bdf37523"
   },
   "outputs": [],
   "source": [
    "tfdfadd_b, words_b = word_frequencies(tfidf_b)\n",
    "print(\"foi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad143b47",
   "metadata": {
    "id": "ad143b47"
   },
   "outputs": [],
   "source": [
    "values, labels = get_top(30,tfdfadd_b,words_b)\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "plt.title(\"Most frequent words / Bad\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.bar(labels,values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a046b2",
   "metadata": {
    "id": "50a046b2"
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5053a387",
   "metadata": {
    "id": "5053a387"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import urllib\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589beac6",
   "metadata": {
    "id": "589beac6"
   },
   "outputs": [],
   "source": [
    "model_data = df_yu.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73961e08",
   "metadata": {
    "id": "73961e08",
    "outputId": "7840edda-9232-49d7-a27d-dde4f6032075"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(model_data, test_size=0.25, random_state=42)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891891b",
   "metadata": {
    "id": "6891891b"
   },
   "outputs": [],
   "source": [
    "X_train = train_data[\"text\"]\n",
    "y_train = train_data[\"isGood\"]\n",
    "X_test = test_data[\"text\"]\n",
    "y_test = test_data[\"isGood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59514928",
   "metadata": {
    "id": "59514928",
    "outputId": "52c5ff54-d446-458c-e928-afd5ab13a641"
   },
   "outputs": [],
   "source": [
    "classificador = Pipeline([\n",
    "                        ('meu_vetorizador', CountVectorizer(stop_words='english')),\n",
    "                        ('meu_classificador', LogisticRegression(penalty=None, solver='saga', max_iter=10000))\n",
    "                        ])\n",
    "classificador.fit(X_train,y_train)\n",
    "y_pred = classificador.predict(X_test)\n",
    "acc = accuracy_score(y_pred,y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af15ece",
   "metadata": {
    "id": "5af15ece",
    "outputId": "b42ba245-beaf-470a-f208-bffcfde29c50"
   },
   "outputs": [],
   "source": [
    "vocabulario = classificador['meu_vetorizador'].vocabulary_\n",
    "pesos = classificador['meu_classificador'].coef_\n",
    "print(pesos.shape)\n",
    "\n",
    "classe_alvo = 0\n",
    "classe_alvo_str = classificador.classes_[classe_alvo]\n",
    "\n",
    "palavras_e_pesos = []\n",
    "for palavra in vocabulario.keys():\n",
    "    j = vocabulario[palavra]\n",
    "    coeficiente = pesos[classe_alvo,j]\n",
    "    palavras_e_pesos.append( (coeficiente, palavra) )\n",
    "\n",
    "tuplas_ordenadas = sorted(palavras_e_pesos, reverse=True) # reverse=True pede uma ordenação em ordem decrescente\n",
    "palavras = [ t[1] for t in tuplas_ordenadas ]\n",
    "contagens = [ t[0] for t in tuplas_ordenadas ]\n",
    "\n",
    "n_palavras = 30\n",
    "eixo_x = np.arange(n_palavras)\n",
    "plt.figure(figsize=(14,1))\n",
    "plt.title('Palavras que mais levam à carta ruim')\n",
    "plt.bar(eixo_x[0:n_palavras], contagens[0:n_palavras])\n",
    "plt.xticks(eixo_x[0:n_palavras], palavras[0:n_palavras], rotation=70)\n",
    "plt.show()\n",
    "\n",
    "eixo_x = np.arange(n_palavras)\n",
    "plt.figure(figsize=(14,1))\n",
    "plt.title('Palavras que mais leva à carta boa')\n",
    "plt.bar(eixo_x[-n_palavras:], contagens[-n_palavras:])\n",
    "plt.xticks(eixo_x[-n_palavras:], palavras[-n_palavras:], rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a6f858",
   "metadata": {
    "id": "26a6f858"
   },
   "source": [
    "## Deep Learning in-house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f72d999",
   "metadata": {
    "id": "7f72d999"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c79c9",
   "metadata": {
    "id": "328c79c9"
   },
   "outputs": [],
   "source": [
    "model_data = df_yu.copy()\n",
    "train_data, test_data = train_test_split(model_data, test_size=0.25, random_state=42)\n",
    "X_train = train_data[\"text\"]\n",
    "y_train = train_data[\"isGood\"]\n",
    "X_test = test_data[\"text\"]\n",
    "y_test = test_data[\"isGood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9ca53",
   "metadata": {
    "id": "6cd9ca53"
   },
   "outputs": [],
   "source": [
    "def pre_processar_saidas(y):\n",
    "    y_out = np.zeros_like(y)\n",
    "    y_out[ y==False ] = -1.0\n",
    "    y_out[ y==True ] = 1.0\n",
    "    y_out = y_out.reshape( (-1, 1))\n",
    "    return y_out.astype(float)\n",
    "\n",
    "y_train_ = pre_processar_saidas(y_train)\n",
    "y_test_ = pre_processar_saidas(y_test)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', binary=True, max_features=500)\n",
    "X_train_ = vectorizer.fit_transform(X_train).todense().astype(float)\n",
    "X_test_ = vectorizer.transform(X_test).todense().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4477b",
   "metadata": {
    "id": "20c4477b",
    "outputId": "1c47466c-0eac-4016-dccd-c50dd066781e"
   },
   "outputs": [],
   "source": [
    "def base_model(vocab_size=500):\n",
    "    input_layer = Input(shape=(vocab_size,))\n",
    "    x = input_layer\n",
    "    x = Dense(1, name='classificador')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "clf = base_model()\n",
    "clf.compile(loss='mean_squared_error', metrics=['accuracy'])\n",
    "clf.fit(X_train_, y_train_, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4811bb",
   "metadata": {
    "id": "1b4811bb",
    "outputId": "e7b0faf8-7aca-4143-c34f-01bd858c0fcb"
   },
   "outputs": [],
   "source": [
    "acc = clf.evaluate(X_test_, y_test_)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096e079",
   "metadata": {
    "id": "2096e079",
    "outputId": "7648ed66-7b93-4c11-e81a-dfcc6e815d81"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_)\n",
    "#print(y_pred.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983e8cc",
   "metadata": {
    "id": "6983e8cc",
    "outputId": "5074aad8-1c68-4a1c-b1f2-40745f3d55d1"
   },
   "outputs": [],
   "source": [
    "print(clf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f398c5",
   "metadata": {
    "id": "79f398c5",
    "outputId": "721f919b-624a-48dc-dab3-a145767f95a6"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(clf.get_layer('classificador').weights[0].shape)\n",
    "print(clf.get_layer('classificador').weights[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135bc1e2",
   "metadata": {
    "id": "135bc1e2",
    "outputId": "e158c634-fdcc-4c86-ae64-4b2811ccb211"
   },
   "outputs": [],
   "source": [
    "clf = base_model()\n",
    "clf.compile(loss='mean_squared_error', metrics=['accuracy'])\n",
    "history = clf.fit(X_train_, y_train_, epochs=5, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e439e5bc",
   "metadata": {
    "id": "e439e5bc",
    "outputId": "aa1d7616-74af-4a12-9b0b-b735934db1eb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,1))\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize=(14,1))\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6677d705",
   "metadata": {
    "id": "6677d705"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y_train_ = ohe.fit_transform(y_train.to_numpy().reshape((-1,1))).todense()\n",
    "y_test_ = ohe.transform(y_test.to_numpy().reshape((-1,1))).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77727551",
   "metadata": {
    "id": "77727551",
    "outputId": "49dfd05f-66a8-493a-f67d-19174e277d8b"
   },
   "outputs": [],
   "source": [
    "def softmax_model(vocab_size=500):\n",
    "    input_layer = Input(shape=(vocab_size,))\n",
    "    x = input_layer\n",
    "    x = Dense(2, name='classificador')(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "clf = softmax_model()\n",
    "print(clf.summary())\n",
    "clf.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = clf.fit(X_train_, y_train_, epochs=5, verbose=1) # validation_split=0.1\n",
    "clf.evaluate(X_test_, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67678d",
   "metadata": {
    "id": "1b67678d",
    "outputId": "5b66a3f7-28e9-422a-9571-cf497cc694e7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_t = np.argmax(np.asarray(y_test_),axis=1).flatten()\n",
    "y_p = np.argmax(clf.predict(X_test_), axis=1)\n",
    "print(y_t.shape)\n",
    "print(y_p.shape)\n",
    "tn, fp, fn, tp = confusion_matrix(y_t, y_p).ravel()\n",
    "print(f\"true negative: {tn}\")\n",
    "print(f\"false positive: {fp}\")\n",
    "print(f\"false negative: {fn}\")\n",
    "print(f\"true negative: {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97be4fc",
   "metadata": {
    "id": "a97be4fc",
    "outputId": "9a5e526d-dceb-4e45-a6c7-56f5cfe93351"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "weights = clf.get_layer('classificador').weights[0].numpy()\n",
    "CLASSE = 0\n",
    "for n in tqdm(range(len(vectorizer.vocabulary_))):\n",
    "    tuplas = [ (weights[vectorizer.vocabulary_[i],CLASSE], i) for i in vectorizer.vocabulary_.keys() ]\n",
    "    tuplas_ordenadas = sorted(tuplas, reverse=True) # reverse=True pede uma ordenação em ordem decrescente\n",
    "    palavras = [ t[1] for t in tuplas_ordenadas ]\n",
    "    contagens = [ t[0] for t in tuplas_ordenadas ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599cb703",
   "metadata": {
    "id": "599cb703",
    "outputId": "9e7b4087-1d65-4c62-af26-65748abe25bc"
   },
   "outputs": [],
   "source": [
    "n_palavras = 20\n",
    "\n",
    "plt.figure(figsize=(14,1))\n",
    "eixo_x = np.arange(n_palavras)\n",
    "plt.bar(eixo_x[0:n_palavras], contagens[0:n_palavras])\n",
    "plt.xticks(eixo_x[0:n_palavras], palavras[0:n_palavras], rotation=70)\n",
    "plt.title(\"Peso das palavras\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e0bb0",
   "metadata": {
    "id": "550e0bb0"
   },
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c462bed",
   "metadata": {
    "id": "6c462bed"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.layers import Input, Dense, Activation, TextVectorization, Embedding, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f6513",
   "metadata": {
    "id": "6f8f6513"
   },
   "outputs": [],
   "source": [
    "model_data = df_yu.copy()\n",
    "ohe = OneHotEncoder()\n",
    "y_ohe = ohe.fit_transform(model_data['isGood'].to_numpy().reshape((-1,1))).todense()\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_data['text'], y_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56742a7b",
   "metadata": {
    "id": "56742a7b",
    "outputId": "b90b7bc4-4a11-4cd3-cde5-b4d1240eda23"
   },
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "def multihot_softmax_model(vectorize_layer, vocab_size=vocab_size):\n",
    "    input_layer = Input(shape=(1,), dtype=tf.string)\n",
    "    x = input_layer\n",
    "    x = vectorize_layer(x)\n",
    "    x = Dense(2, name='classificador')(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "vectorize_layer = TextVectorization(output_mode='multi_hot', max_tokens=vocab_size, pad_to_max_tokens=True)\n",
    "vectorize_layer.adapt(X_train)\n",
    "clf = multihot_softmax_model(vectorize_layer)\n",
    "print(clf.summary())\n",
    "clf.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = clf.fit(X_train, y_train, epochs=30, verbose=1) # validation_split=0.1\n",
    "clf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389125a6",
   "metadata": {
    "id": "389125a6",
    "outputId": "a1e85f79-ec28-46ed-f480-522250409313"
   },
   "outputs": [],
   "source": [
    "arr =np.argmax(clf.predict(X_test),axis=1)\n",
    "\n",
    "# Get unique values and their counts\n",
    "unique_values, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "# Print the unique values and their counts\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value} occurs {count} times\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809aa427",
   "metadata": {
    "id": "809aa427",
    "outputId": "fc6ad6ac-1cdf-47d2-80d7-55816847a38d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_t = np.argmax(np.asarray(y_test),axis=1).flatten()\n",
    "y_p = np.argmax(clf.predict(X_test), axis=1)\n",
    "print(y_t.shape)\n",
    "print(y_p.shape)\n",
    "tn, fp, fn, tp = confusion_matrix(y_t, y_p).ravel()\n",
    "print(f\"true negative: {tn}\")\n",
    "print(f\"false positive: {fp}\")\n",
    "print(f\"false negative: {fn}\")\n",
    "print(f\"true negative: {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46df080",
   "metadata": {
    "id": "d46df080",
    "outputId": "6cca1200-4df5-4471-cf24-fb5ef154525c"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Visualização: onde foi parar cada palavra?\n",
    "projecoes = clf.get_layer('classificador').get_weights()[0]\n",
    "vocabulario = vectorize_layer.get_vocabulary()\n",
    "y_pred_ohe = clf.predict(vocabulario)\n",
    "y_pred = ohe.inverse_transform(y_pred_ohe)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['dim_1'] = projecoes[:,0]\n",
    "df['dim_2'] = projecoes[:,1]\n",
    "df['word'] = vocabulario\n",
    "df['prediction'] = y_pred\n",
    "\n",
    "px.scatter(df, x=\"dim_1\", y=\"dim_2\", color=\"prediction\", hover_data=[\"word\"], title=\"Onde foi cada palavra?\", width=600, height=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09ae51",
   "metadata": {
    "id": "6d09ae51",
    "outputId": "82c6302a-e68f-4bcf-c1c7-036148aa538c"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "#df = pd.read_csv('embeddings_over_epochs.csv') # Gravei esse arquivo antecipadamente - demora muito para refazê-lo!\n",
    "df.head()\n",
    "df['prediction'][0] = 'positive' # Isso é definitivamente um hack. Sem isso, o plotly não vê o label 'positive' na primeira época, e começa a remover o label 'positive' dos plots subsequentes.\n",
    "\n",
    "px.scatter(df, x=\"dim_1\", y=\"dim_2\", animation_group=\"word\",\n",
    "            color=\"prediction\", hover_name=\"word\", title=\"Training a 2D word embedding for sentiment analysis <br><sup>Where did each word go in the embedding space?</sup>\",\n",
    "          range_x=[-15,15], range_y=[-15,15],\n",
    "          width=800, height=800\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e55474",
   "metadata": {
    "id": "52e55474"
   },
   "source": [
    "## Rede Pré-Treinada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a926588",
   "metadata": {
    "id": "8a926588"
   },
   "outputs": [],
   "source": [
    "model_data = df_yu.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FvECLtby64Ci",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvECLtby64Ci",
    "outputId": "07d0732c-e95a-4660-936e-9c4921a99c43"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "r-dNkl0NEtMk",
   "metadata": {
    "id": "r-dNkl0NEtMk"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from transformers import TFAutoModel\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "def load_pretrained_model(vocab_size):\n",
    "    # Load the pre-trained model\n",
    "    pretrained_model = TFAutoModel.from_pretrained('google/mobilebert-uncased')\n",
    "\n",
    "\n",
    "    # Remove the softmax layer from the pre-trained model\n",
    "    pretrained_model.layers.pop() \n",
    "\n",
    "    # Freeze the weights of the pre-trained layers\n",
    "    for layer in pretrained_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Create the new model architecture\n",
    "    input_layer = Input(shape=(1,), dtype=tf.string)\n",
    "    x = input_layer\n",
    "    x = vectorize_layer(x)\n",
    "    x = tf.cast(x, tf.int32)  # Cast the vectorized input to int32\n",
    "    x = pretrained_model(x)[0]  # Use only the pooled output\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)  # Pooling layer to reduce dimensions\n",
    "    x = Dense(2, name='classificador')(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    \n",
    "    model = Model(input_layer, x)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23abbc42",
   "metadata": {
    "id": "23abbc42"
   },
   "outputs": [],
   "source": [
    "model_data = df_yu.copy()\n",
    "ohe = OneHotEncoder()\n",
    "y_ohe = ohe.fit_transform(model_data['isGood'].to_numpy().reshape((-1,1))).todense()\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_data['text'], y_ohe)\n",
    "\n",
    "#ohe = OneHotEncoder()\n",
    "y_t = model_data['isGood']\n",
    "#y_ohe = ohe.fit_transform(model_data['isGood'].to_numpy().reshape((-1,1))).todense()\n",
    "X = model_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qVCp4hmSGImq",
   "metadata": {
    "id": "qVCp4hmSGImq"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextVectorization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m----> 3\u001b[0m vectorize_layer \u001b[38;5;241m=\u001b[39m \u001b[43mTextVectorization\u001b[49m(output_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti_hot\u001b[39m\u001b[38;5;124m'\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39mvocab_size, pad_to_max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m vectorize_layer\u001b[38;5;241m.\u001b[39madapt(X_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextVectorization' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000\n",
    "\n",
    "vectorize_layer = TextVectorization(output_mode='multi_hot', max_tokens=vocab_size, pad_to_max_tokens=True)\n",
    "vectorize_layer.adapt(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tJJ9A_WiGNQR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJJ9A_WiGNQR",
    "outputId": "98274f14-9045-49d7-82a5-1b5ec72d1fdc"
   },
   "outputs": [],
   "source": [
    "clf = load_pretrained_model(vocab_size)\n",
    "print(clf.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KRSz4370GNSp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRSz4370GNSp",
    "outputId": "06f8185d-e927-4117-d7fa-7969a6ae7914"
   },
   "outputs": [],
   "source": [
    "\n",
    "clf.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#history = clf.fit(X_train, y_train, epochs=30, verbose=1) # validation_split=0.1\n",
    "#X_test_vectorized = vectorize_layer(X_test).numpy()\n",
    "evaluation = clf.evaluate(X_test, y_test)\n",
    "print(\"Loss:\", evaluation[0])\n",
    "print(\"Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dZELvfI2GNWC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZELvfI2GNWC",
    "outputId": "919a4e41-9399-4de1-d8ee-524b21635ef9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_t = np.argmax(np.asarray(y_test),axis=1).flatten()\n",
    "y_p = np.argmax(clf.predict(X_test), axis=1)\n",
    "print(y_t.shape)\n",
    "print(y_p.shape)\n",
    "tn, fp, fn, tp = confusion_matrix(y_t, y_p).ravel()\n",
    "print(f\"true negative: {tn}\")\n",
    "print(f\"false positive: {fp}\")\n",
    "print(f\"false negative: {fn}\")\n",
    "print(f\"true negative: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VQILE5T4d4cD",
   "metadata": {
    "id": "VQILE5T4d4cD"
   },
   "source": [
    "## Pos Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e16d0",
   "metadata": {
    "id": "8c9e16d0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa323320",
   "metadata": {
    "id": "fa323320"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3336a",
   "metadata": {
    "id": "fcb3336a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62062df",
   "metadata": {
    "id": "e62062df"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ffe01f",
   "metadata": {
    "id": "68ffe01f"
   },
   "outputs": [],
   "source": [
    "df_yugi.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a66b65",
   "metadata": {
    "id": "45a66b65"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "model = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935716c0",
   "metadata": {
    "id": "935716c0"
   },
   "outputs": [],
   "source": [
    "embeddings=model(df_yugi[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e78255",
   "metadata": {
    "id": "b3e78255"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_yugi = PCA(n_components=5)\n",
    "principalComponents_yugi = pca_yugi.fit_transform(embeddings)\n",
    "principalComponents_yugi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e5d18",
   "metadata": {
    "id": "770e5d18"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(principalComponents_yugi, columns=['pca1', 'pca2','pca3','pca4','pca5'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
