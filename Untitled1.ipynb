{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2a56fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_300\\341479595.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_yugi = pd.read_csv('dbs/yugi_comp.csv',engine=\"python\",error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import psutil\n",
    "print(\"Hello World\")\n",
    "df_yugi = pd.read_csv('dbs/yugi_comp.csv',engine=\"python\",error_bad_lines=False)\n",
    "df_yugi = df_yugi.drop(['name'], axis=1)\n",
    "df_yugi = df_yugi[df_yugi['text'].notna()]\n",
    "df_yugi.head()\n",
    "import math\n",
    "def getMonsterType(row):\n",
    "    if row['card_type'] == 'monster':\n",
    "        monstype = row['type'].split(\"/\")\n",
    "        return monstype[-1].replace(\" \",\"\")\n",
    "    else:\n",
    "        return math.nan\n",
    "df_yugi['monster_type'] = df_yugi.apply(lambda row: getMonsterType(row), axis=1)\n",
    "df_yu = df_yugi.loc[(df_yugi['monster_type'] != 'Normal')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b411f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbb1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"Baseline\",\"DeepLearn\",\"SoftMax\",\"Embedding\",\"PreTrain\",\"PostTreat\"]\n",
    "delays = {}\n",
    "ram = {}\n",
    "accuracies = {}\n",
    "fps = {}\n",
    "tps = {}\n",
    "fns = {}\n",
    "tns = {}\n",
    "\n",
    "def startmeasuring():\n",
    "    # Start measuring time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Start measuring RAM usage\n",
    "    start_ram = psutil.Process().memory_info().rss\n",
    "    return start_time,start_ram\n",
    "\n",
    "def finishmeasuring(start_time,start_ram):\n",
    "    # Stop measuring time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Stop measuring RAM usage\n",
    "    end_ram = psutil.Process().memory_info().rss\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Calculate RAM usage\n",
    "    ram_usage = end_ram - start_ram\n",
    "\n",
    "    return elapsed_time, ram_usage\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion = 'true negative', 'false positive', 'false negative', 'true positive'\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def build_confusion_matrix(y_test_,y_pred,method):\n",
    "  y_t = y_test_\n",
    "  y_p = y_pred\n",
    "  print(y_t.shape)\n",
    "  print(y_p.shape)\n",
    "  tn, fp, fn, tp = confusion_matrix(y_t, y_p).ravel()\n",
    "  print(f\"{confusion[0]}: {tn}\")\n",
    "  print(f\"{confusion[1]}: {fp}\")\n",
    "  print(f\"{confusion[2]}: {fn}\")\n",
    "  print(f\"{confusion[3]}: {tp}\")\n",
    "  sizes = [tn, fp, fn, tp]\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.pie(sizes, labels=confusion, autopct='%1.1f%%')\n",
    "\n",
    "  tns[method] = tn\n",
    "  fps[method]= fp\n",
    "  fns[method] =fn\n",
    "  tps[method] =tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baafa25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8668df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.layers import Input, Dense, Activation, TextVectorization, Embedding, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6077ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = df_yu.copy()\n",
    "method = methods[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d3099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "def load_pretrained_model(vocab_size):\n",
    "    # Load the pre-trained model\n",
    "    pretrained_model = TFAutoModel.from_pretrained('google/mobilebert-uncased')\n",
    "\n",
    "\n",
    "    # Remove the softmax layer from the pre-trained model\n",
    "    pretrained_model.layers.pop() \n",
    "\n",
    "    # Freeze the weights of the pre-trained layers\n",
    "    for layer in pretrained_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Create the new model architecture\n",
    "    input_layer = Input(shape=(1,), dtype=tf.string)\n",
    "    x = input_layer\n",
    "    x = vectorize_layer(x)\n",
    "    x = tf.cast(x, tf.int32)  # Cast the vectorized input to int32\n",
    "    x = pretrained_model(x)[0]  # Use only the pooled output\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)  # Pooling layer to reduce dimensions\n",
    "    x = Dense(2, name='classificador')(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    \n",
    "    model = Model(input_layer, x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "173c8174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/mobilebert-uncased were not used when initializing TFMobileBertModel: ['seq_relationship___cls', 'predictions___cls']\n",
      "- This IS expected if you are initializing TFMobileBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFMobileBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFMobileBertModel were initialized from the model checkpoint at google/mobilebert-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMobileBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_2 (TextV  (None, 500)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " tf.cast_1 (TFOpLambda)      (None, 500)               0         \n",
      "                                                                 \n",
      " tf_mobile_bert_model_1 (TFM  TFBaseModelOutputWithPoo  24581888 \n",
      " obileBertModel)             ling(last_hidden_state=(            \n",
      "                             None, 500, 512),                    \n",
      "                              pooler_output=(None, 51            \n",
      "                             2),                                 \n",
      "                              hidden_states=None, att            \n",
      "                             entions=None)                       \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " classificador (Dense)       (None, 2)                 1026      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,582,914\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 24,581,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_data = df_yu.copy()\n",
    "ohe = OneHotEncoder()\n",
    "y_ohe = ohe.fit_transform(model_data['isGood'].to_numpy().reshape((-1,1))).todense()\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_data['text'], y_ohe)\n",
    "\n",
    "#ohe = OneHotEncoder()\n",
    "y_t = model_data['isGood']\n",
    "#y_ohe = ohe.fit_transform(model_data['isGood'].to_numpy().reshape((-1,1))).todense()\n",
    "X = model_data['text']\n",
    "\n",
    "vocab_size = 500\n",
    "\n",
    "vectorize_layer = TextVectorization(output_mode='multi_hot', max_tokens=vocab_size, pad_to_max_tokens=True)\n",
    "vectorize_layer.adapt(X_train)\n",
    "\n",
    "clf = load_pretrained_model(vocab_size)\n",
    "print(clf.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e4a18d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 1214s 13s/step - loss: 46515.3477 - accuracy: 0.1749\n",
      "Loss: 46515.34765625\n",
      "Accuracy: 0.1748768538236618\n"
     ]
    }
   ],
   "source": [
    "clf.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#history = clf.fit(X_train, y_train, epochs=30, verbose=1) # validation_split=0.1\n",
    "#X_test_vectorized = vectorize_layer(X_test).numpy()\n",
    "evaluation = clf.evaluate(X_test, y_test)\n",
    "print(\"Loss:\", evaluation[0])\n",
    "print(\"Accuracy:\", evaluation[1])\n",
    "acc = evaluation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe3384b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
